version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: ./compose/local/django/Dockerfile
    image: scraper
    networks:
      - scraper_network
      # '/start' is the shell script used to run the service
    command: /start
    # this volume is used to map the files and folders on the host to the container
    # so if we change code on the host, code in the docker container will also be changed
    volumes:
      - ./app:/app
    ports:
      - 8010:8000
    # env_file is used to manage the env variables of our project
    env_file:
      - ./.env/.dev-sample
    depends_on:
      - scraper_rabbitmq
      - redis
      - scraperdb
      - chrome

  scraperdb:
    image: postgres:14-alpine
    container_name: "scraperdb"
    networks:
      - scraper_network
    volumes:
      - dev-scraperdb-data:/var/lib/postgresql/data/
    environment:
      - POSTGRES_DB=hello_django
      - POSTGRES_USER=hello_django
      - POSTGRES_PASSWORD=hello_django

  scraper_rabbitmq:
    image: rabbitmq:latest
    networks:
      - scraper_network
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    environment:
      - RABBITMQ_DEFAULT_USER=admin
      - RABBITMQ_DEFAULT_PASS=mypass
    ports:
      # Expose the port for the worker to add/get tasks
      - 5672:5672
      # OPTIONAL: Expose the GUI port
      - 15672:15672

  redis:
    image: redis:7-alpine
    networks:
      - scraper_network
    volumes:
      - ./redis_data:/data

  celery_worker:
    build:
      context: .
      dockerfile: ./compose/local/django/Dockerfile
    image: scraper_celery_worker
    networks:
      - scraper_network
    command: /start-celeryworker
    volumes:
      - ./app:/app
    env_file:
      - ./.env/.dev-sample
    depends_on:
      - scraper_rabbitmq
      - redis
      - scraperdb

  celery_beat:
    build:
      context: .
      dockerfile: ./compose/local/django/Dockerfile
    image: scraper_celery_beat
    networks:
      - scraper_network
    command: /start-celerybeat
    volumes:
      - ./app:/app
    env_file:
      - ./.env/.dev-sample
    depends_on:
      - scraper_rabbitmq
      - redis
      - scraperdb

  flower:
    build:
      context: .
      dockerfile: ./compose/local/django/Dockerfile
    image: scraper_celery_flower
    networks:
      - scraper_network
    command: /start-flower
    volumes:
      - ./app:/app
    env_file:
      - ./.env/.dev-sample
    ports:
      - 5557:5555
    depends_on:
      - scraper_rabbitmq
      - redis
      - scraperdb

  chrome:
    image: "selenium/standalone-chrome:latest"
    container_name: "chrome"
    environment:
      - SE_VNC_NO_PASSWORD=1
    networks:
      - scraper_network
    hostname: chrome
    shm_size: '2gb'
    restart: always
    ports:
      - "4444:4444"

volumes:
  dev-scraperdb-data:
  redis-data:
  rabbitmq_data:


networks:
  scraper_network:
    name: scraper_network
    driver: bridge
    ipam:
      config:
        - subnet: 192.168.95.0/24
